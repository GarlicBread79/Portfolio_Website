# -*- coding: utf-8 -*-
"""CS 464 Project - Fake News Detection System

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v1GwFAL6BtNShspY2q8DJrqhXw84YWjS

from google.colab import drive
drive.mount('/content/drive')
"""

import os

# List all files in the archive folder
archive_path = '/content/drive/MyDrive/archive'
files = os.listdir(archive_path)

print("Files in archive folder:")
print(files)

import os

# Path to the archive folder
archive_path = '/content/drive/MyDrive/archive'

# List all files and their types
files = os.listdir(archive_path)

print("Files in the archive folder:")
for file in files:
    print(file)

import os

# Path to the archive folder

# List all files with their extensions
files = os.listdir(archive_path)

print("Files in the archive folder:")
for file in files:
    file_path = os.path.join(archive_path, file)
    print(f"{file}: Is Directory? {os.path.isdir(file_path)}")

import os

# Path to the archive folder
archive_path = '/content/drive/MyDrive/archive'

# List contents of each directory
for folder in ['overall', 'training', 'Testing_dataset']:
    folder_path = os.path.join(archive_path, folder)
    print(f"Contents of {folder}:")
    print(os.listdir(folder_path))

import os
import pandas as pd

# Define the directories to inspect
archive_path = '/content/drive/MyDrive/archive'
directories = ['overall', 'training', 'Testing_dataset']

# Check the type of contents and process files
for directory in directories:
    dir_path = os.path.join(archive_path, directory)
    contents = os.listdir(dir_path)  # List items in the directory

    for item in contents:
        item_path = os.path.join(dir_path, item)

        # If the item is a file, check its extension and process
        if not os.path.isdir(item_path):  # Ensure it's a file, not a directory
            print(f"Processing file: {item}")

            # Check file type and process accordingly
            if item.endswith('.csv'):  # Handle CSV files
                data = pd.read_csv(item_path)
                print(data.head())
            elif item.endswith('.json'):  # Handle JSON files
                data = pd.read_json(item_path)
                print(data.head())
            elif item.endswith('.xlsx'):  # Handle Excel files
                data = pd.read_excel(item_path)
                print(data.head())
            else:
                print(f"Unsupported file format: {item}")
        else:
            print(f"{item} is a directory, not a file.")

import os
import pandas as pd

# Define the base path and the subdirectories
archive_path = '/content/drive/MyDrive/archive'
directories = ['overall', 'training', 'Testing_dataset']

# Navigate through each directory and its contents
for directory in directories:
    dir_path = os.path.join(archive_path, directory)
    print(f"Inspecting contents of directory: {directory}")

    # List the contents of the current directory
    contents = os.listdir(dir_path)

    for item in contents:
        item_path = os.path.join(dir_path, item)

        # Check if the item is a file or a subdirectory
        if os.path.isdir(item_path):  # If it's another subdirectory
            print(f"{item} is a subdirectory. Listing its contents:")
            sub_contents = os.listdir(item_path)
            for sub_item in sub_contents:
                sub_item_path = os.path.join(item_path, sub_item)
                print(f"Processing file: {sub_item}")

                # Process files based on their extensions
                if sub_item.endswith('.csv'):
                    data = pd.read_csv(sub_item_path)
                    print(data.head())
                elif sub_item.endswith('.json'):
                    data = pd.read_json(sub_item_path)
                    print(data.head())
                elif sub_item.endswith('.xlsx'):
                    data = pd.read_excel(sub_item_path)
                    print(data.head())
                else:
                    print(f"Unsupported file format: {sub_item}")
        else:  # If it's a file
            print(f"Processing file: {item}")
            if item.endswith('.csv'):
                data = pd.read_csv(item_path)
                print(data.head())
            elif item.endswith('.json'):
                data = pd.read_json(item_path)
                print(data.head())
            elif item.endswith('.xlsx'):
                data = pd.read_excel(item_path)
                print(data.head())
            else:
                print(f"Unsupported file format: {item}")

import pandas as pd
import os

# Define paths to the CSV files
fake_articles_path = '/content/drive/MyDrive/archive/Testing_dataset/testingSet/Catalog - Fake Articles.csv'
real_articles_path = '/content/drive/MyDrive/archive/Testing_dataset/testingSet/Catalog - Real Articles.csv'

# Load the fake articles dataset
fake_data = pd.read_csv(fake_articles_path)
print("Fake Articles Dataset:")
print(fake_data.head())

# Load the real articles dataset
real_data = pd.read_csv(real_articles_path)
print("\nReal Articles Dataset:")
print(real_data.head())

# Extract relevant columns (e.g., 'Title', 'Article') and add labels
fake_data = fake_data[['Title', 'Article']].copy()
fake_data['Label'] = 1  # Label fake news as 1

real_data = real_data[['Title', 'Article']].copy()
real_data['Label'] = 0  # Label real news as 0

# Combine the datasets
combined_data = pd.concat([fake_data, real_data], ignore_index=True)

# Shuffle the dataset
combined_data = combined_data.sample(frac=1, random_state=42).reset_index(drop=True)

print("\nCombined Dataset:")
print(combined_data.head())

# Drop unnecessary columns (e.g., 'Unnamed: 5', 'Unnamed: 6', etc.)
combined_data = combined_data.dropna(subset=['Title', 'Article'])
print("\nCleaned Combined Dataset:")
print(combined_data.info())

# Save the combined dataset
processed_dataset_path = '/content/drive/MyDrive/archive/Testing_dataset/processed_data.csv'
combined_data.to_csv(processed_dataset_path, index=False)

print(f"\nProcessed dataset saved to: {processed_dataset_path}")

# Step 1
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score

# Load the combined processed dataset
processed_dataset_path = '/content/drive/MyDrive/archive/Testing_dataset/processed_data.csv'
data = pd.read_csv(processed_dataset_path)

# Check the dataset structure
print("Dataset Overview:")
print(data.head())
print("\nDataset Info:")
print(data.info())

# Extract features (articles) and labels
X = data['Article']  # Features: Article text
y = data['Label']    # Labels: 1 for fake, 0 for real

# Split the dataset into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Step 2
from sklearn.linear_model import LogisticRegression

# Vectorize text data using TF-IDF
tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

# Train a Logistic Regression model
baseline_model = LogisticRegression(max_iter=1000, random_state=42)
baseline_model.fit(X_train_tfidf, y_train)

# Evaluate the model
y_pred_baseline = baseline_model.predict(X_test_tfidf)
y_pred_probs_baseline = baseline_model.predict_proba(X_test_tfidf)[:, 1]

print("\nBaseline Model (Logistic Regression) Results:")
print("Accuracy:", accuracy_score(y_test, y_pred_baseline))
print("ROC-AUC:", roc_auc_score(y_test, y_pred_probs_baseline))
print("\nClassification Report:\n", classification_report(y_test, y_pred_baseline))

# Logistic Regression Results
print("\nBaseline Model - Logistic Regression:")
print(f"Accuracy: {accuracy_score(y_test, y_pred_baseline):.2f}")
print(f"ROC-AUC: {roc_auc_score(y_test, y_pred_probs_baseline):.2f}")

# BERT Results
print("\nOracle Model - BERT:")
print(f"Accuracy: {test_results[1]:.2f}")

# Step 1

# Import libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score
from transformers import BertTokenizer, TFBertForSequenceClassification
from tensorflow.keras.optimizers import Adam
import tensorflow as tf

# Load the processed dataset
processed_dataset_path = '/content/drive/MyDrive/archive/Testing_dataset/processed_data.csv'
df = pd.read_csv(processed_dataset_path)

# Explore and clean the dataset
print("Dataset Overview:")
print(df.head())

# Extract features (Article text) and labels (1: Fake, 0: Real)
X = df['Article']
y = df['Label']

# Split dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print(f"Training set size: {len(X_train)}")
print(f"Test set size: {len(X_test)}")

# Step 2

from sklearn.linear_model import LogisticRegression

# Vectorize the text using TF-IDF
tfidf_vectorizer = TfidfVectorizer(stop_words="english", max_df=0.7)
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

# Train the Logistic Regression model
logistic_model = LogisticRegression(max_iter=1000, random_state=42)
logistic_model.fit(X_train_tfidf, y_train)

# Make predictions
y_pred_baseline = logistic_model.predict(X_test_tfidf)
y_prob_baseline = logistic_model.predict_proba(X_test_tfidf)[:, 1]

# Evaluate the Logistic Regression model
print("\nBaseline Model - Logistic Regression")
print(f"Accuracy: {accuracy_score(y_test, y_pred_baseline):.2f}")
print(f"ROC-AUC: {roc_auc_score(y_test, y_prob_baseline):.2f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred_baseline))

# Step 3

from transformers import BertTokenizer, TFBertForSequenceClassification, create_optimizer
from tensorflow.keras.losses import SparseCategoricalCrossentropy
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score
import tensorflow as tf
# Load BERT tokenizer and model
bert_tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
bert_model = TFBertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=2)

# Tokenize the text data
def encode_texts(texts, tokenizer, max_len=256):
    return tokenizer(
        list(texts),
        max_length=max_len,
        truncation=True,
        padding="max_length",
        return_tensors="tf"
    )

X_train_encoded = encode_texts(X_train, bert_tokenizer)
X_test_encoded = encode_texts(X_test, bert_tokenizer)

# Define optimizer parameters
batch_size = 16
epochs = 3
num_train_steps = (len(X_train) // batch_size) * epochs
num_warmup_steps = num_train_steps // 10

# Create an optimizer with weight decay
optimizer, lr_schedule = create_optimizer(
    init_lr=5e-5,
    num_train_steps=num_train_steps,
    num_warmup_steps=num_warmup_steps,
    weight_decay_rate=0.01
)

# Compile the BERT model
bert_model.compile(
    optimizer=optimizer,
    loss=SparseCategoricalCrossentropy(from_logits=True),
    metrics=["accuracy"]
)

# Train the BERT model
bert_model.fit(
    {'input_ids': X_train_encoded["input_ids"], 'attention_mask': X_train_encoded["attention_mask"]},
    y_train,
    validation_split=0.1,
    epochs=3,
    batch_size=16
)

# Evaluate the BERT model
y_pred_oracle = bert_model.predict(
    {'input_ids': X_test_encoded["input_ids"], 'attention_mask': X_test_encoded["attention_mask"]}
).logits
y_pred_oracle_labels = tf.argmax(y_pred_oracle, axis=1).numpy()

# Evaluate the performance
print("\nOracle Model - Fine-tuned BERT")
print(f"Accuracy: {accuracy_score(y_test, y_pred_oracle_labels):.2f}")
print(f"ROC-AUC: {roc_auc_score(y_test, tf.nn.softmax(y_pred_oracle)[:, 1]):.2f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred_oracle_labels))

# Baseline Model Results
print("\nBaseline Model (Logistic Regression):")
print(f"Accuracy: {accuracy_score(y_test, y_pred_baseline):.2f}")
print(f"ROC-AUC: {roc_auc_score(y_test, y_prob_baseline):.2f}")

# Oracle Model Results
print("\nOracle Model (BERT):")
print(f"Accuracy: {accuracy_score(y_test, y_pred_oracle_labels):.2f}")
print(f"ROC-AUC: {roc_auc_score(y_test, tf.nn.softmax(y_pred_oracle)[:, 1]):.2f}")

import matplotlib.pyplot as plt
import pandas as pd

def generate_charts():
    # This will remove the
    data = {
        "Model": ["Logistic Regression", "BERT"],
        "Accuracy": [85, 50],
        "ROC-AUC": [87, 66]
    }
    df = pd.DataFrame(data)

    # Plot Accuracy Comparison
    plt.figure(figsize=(8, 5))
    plt.bar(df["Model"], df["Accuracy"], color=["blue", "orange"])
    plt.title("Model Accuracy Comparison", fontsize=14)
    plt.ylabel("Accuracy (%)", fontsize=12)
    plt.ylim(0, 100)
    plt.xticks(fontsize=12)
    plt.yticks(fontsize=12)
    plt.grid(axis="y", linestyle="--", alpha=0.7)
    plt.savefig("model_accuracy_comparison.png")  # Save accuracy chart
    plt.show()  # Display the accuracy chart
    plt.close()

    # Plot ROC-AUC Comparison
    plt.figure(figsize=(8, 5))
    plt.bar(df["Model"], df["ROC-AUC"], color=["green", "purple"])
    plt.title("Model ROC-AUC Comparison", fontsize=14)
    plt.ylabel("ROC-AUC (%)", fontsize=12)
    plt.ylim(0, 100)
    plt.xticks(fontsize=12)
    plt.yticks(fontsize=12)
    plt.grid(axis="y", linestyle="--", alpha=0.7)
    plt.savefig("model_roc_auc_comparison.png")  # Save ROC-AUC chart
    plt.show()  # Display the ROC-AUC chart
    plt.close()

# Call the function to generate and display charts
generate_charts()

import streamlit as st
from transformers import BertTokenizer, TFBertForSequenceClassification
import tensorflow as tf

# Load model and tokenizer
model = TFBertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=2)
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

# Streamlit UI
st.title("Fake News Detector")
user_input = st.text_area("Enter a news article text:", "")

if st.button("Check"):
    if user_input.strip():
        inputs = tokenizer(user_input, return_tensors="tf", max_length=512, truncation=True, padding="max_length")
        logits = model(inputs["input_ids"], inputs["attention_mask"]).logits
        prediction = tf.argmax(logits, axis=1).numpy()[0]
        result = "Fake News" if prediction == 1 else "Real News"
        st.write(f"Prediction: **{result}**")
    else:
        st.write("Please enter a valid text.")